# SOOG Backend (Flask)

A Flask-based API that powers SOOG. It provides:

- /api/generate: Calls DeepSeek chat completion and optionally returns code or a rendered matplotlib plot.
- /api/predict: Runs a small multimodal model (DistilBERT + CLIP + attention head) on text + image.
- /api/somap/*: Simple CRUD endpoints backed by ArangoDB collections.
- /api/version: Returns backend version from `version.txt`.
- /api/health: Lightweight health check with version and device info.
- /log: HTML view of structured JSON logs.

## Requirements

- Python 3.10+
- macOS or Linux recommended
- Optional: NVIDIA GPU + CUDA for faster Torch inference
- Optional: Redis if you plan to use the cache utilities (not wired by default in `app.py` yet)
- ArangoDB if you use the `/api/somap/*` endpoints

Python dependencies are listed in `requirements.txt` (includes torch, transformers, matplotlib, python-arango, etc.).

## Environment variables

Copy `.env.example` to `.env` and fill in values:

- DEEPSEEK_API_KEY: API key for DeepSeek chat.
- PORT: Port for Flask (default 10000).
- HF_HOME: Optional path for Hugging Face cache (defaults to `./.cache/huggingface`).
- ARANGO_URL: e.g. http://localhost:8529
- ARANGO_DB: Database name, e.g. `somap`
- ARANGO_USER: Username, e.g. `root`
- ARANGO_PASS: Password (don’t hardcode secrets in code).

Note: `app.py` currently defines a default password if env is missing; prefer setting ARANGO_* in `.env` for safety.

## Running locally (fish shell)

```fish
# 1) Create and activate a virtualenv
python3 -m venv venv
source venv/bin/activate.fish

# 2) Install dependencies
pip install -r requirements.txt

# 3) Set env (if you didn’t create .env yet)
set -gx DEEPSEEK_API_KEY "sk-..."
set -gx PORT 10000
# Optional Arango settings
set -gx ARANGO_URL "http://localhost:8529"
set -gx ARANGO_DB "somap"
set -gx ARANGO_USER "root"
set -gx ARANGO_PASS "<your-pass>"

# 4) Run the server
python app.py
```

### Or use the Makefile (works from any shell)

```fish
# install deps into venv/
make install

# quick import sanity check
make check

# run the server on default port 10000
make run

# override port
make run PORT=11000
```

### One-shot dev script

```fish
chmod +x scripts/dev.sh
PORT=10000 bash scripts/dev.sh
```

The server listens on 0.0.0.0:$PORT (default 10000). Health check:

- GET http://localhost:10000/api/health

## Notes

- Heavy models: The `/api/predict` endpoint loads DistilBERT and CLIP and an attention head; first call can be slow due to downloads. Models are cached under `./.cache/huggingface`.
- Checkpoints: If `modeltrainer/outputModel/multimodal_model_final.pth` exists, it will be loaded.
- Logs: Structured JSON logs are written to `backend/logs/app.json`. View logs at `/log`.
- CORS: Enabled for `/api/*` and `/log`.

## Troubleshooting

- DeepSeek 401/403: Ensure `DEEPSEEK_API_KEY` is set in your environment.
- Arango connection errors: Verify Arango is running and your ARANGO_* env values are correct.
- Torch/transformers install: On macOS with ARM, some combos may be slow or need extra wheels; you can temporarily disable `/api/predict` if not needed.
- Port conflict: If 5000 is in use, use `PORT=10000` (the default in app.py) and run again.

## Optional: Redis cache

`cache_*.py` implements a Redis-based cache manager and decorators. If you want to enable caching in routes, start a Redis server locally and wire the decorators in `app.py` accordingly. Redis defaults to `localhost:6379` DB 0/1 per `cache_config.py`.
